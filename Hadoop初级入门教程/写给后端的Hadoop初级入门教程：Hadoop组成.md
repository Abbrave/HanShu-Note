# 写给后端的Hadoop初级入门教程：Hadoop组成部分。

## 前言：

在上一篇文章[写给后端的Hadoop初级入门教程：概念篇](https://juejin.im/post/5dec7ec5e51d45581e43ff17)中，我们主要讲了大数据的简单概念，什么是大数据，大数据的特点是什么？之后我们又从大数据扩展到`Hadoop`，讲了三个最主要的问题，`Hadoop`是什么，`Hadoop`发展史，`Hadoop`相较于其他大数据框架而言优势又是什么?

今天呢，我们依然沿着上一篇的脉络，去探索`Hadoop`的基本组成部分，是哪些技术有机地组合在了一起造就了`Hadoop`今天在大数据领域的出色表现，在`Hadoop2.0`之后，`Hadoop`主要由以下三个部分组成：

- `Map - Reduce` ：负责计算
- `Yarn` ：负责资源调度
- `HDFS`: 负责数据的存储

它们三个相辅相成，互相成就，当然本篇文章今天只是初略地带大家理解一下这三种技术在`Hadoop`中所起到的作用，具体更加详细的细节，在我们之后关于`Map-Reduce`和`HDFS`专题中会做更加详细的概述。

## Map-Ruduce编程模型：

首先平常看到这种英语概念，第一时间就是打开我们的谷歌翻译，Map的意思我想大家都知道，毕竟`java`中用的不能再多，`Reduce`是降低减少归纳的意思，所以Map-Reduce就是一个先分隔（map）再归纳（Reduce)的过程。

我们来看下定义：

`MapReduce`是一个分布式运算程序的编程框架，是用户开发“基于`Hadoop`的数据分析应用”的核心框架。核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，**并发运行**在一个`Hadoop`集群上。

**`MapReduce`主要可以概括为`map`阶段和`reduce`阶段。** 

只看定义确实是有点晦涩，那Map-Reduce通俗理解是什么呢？还是我们上一篇文章讲的那个例子：

初中的时候，男生爱看玄幻小说，因为怕被教导主任查到，于是采用分布式存储的方案，把书分成几页几页的，放在不同的同学那边放着，但教导主任不是傻子，所谓道高一尺魔高一丈，最后还是被发现了，而是还放言今天要是不把这本书凑齐交到他办公室，全部都等着叫家长吧。

最后大家都把手里的残本交给了班长小明，小明根据页码排序整理好，交给了教导主任。

教导主任说你这不是闲的吗，天天不好好学习搁那看的这什么，**头破苍穹**，是英语书不好背了，还是数学书不好看了？这么着，你不是闲得慌吗，就这个**萧炎**，就他，你下去给我查查，整本书这个名字一共出现了多少次！不查完今天别想吃饭了！

小明想，这不是玩完了，我自己查，我得查到猴年马月才能查完。

> 重点来了，传统的编程模型要是需要知道一本书中某个单词出现的频率，只能写个程序，遍历整个文件，如果几个字还好说，但是把斗破苍穹遍历一遍，需要的时间绝对够你吃顿饭的。
>
> 那不是还有多线程吗？
>
> 是有多线程，但是前提是我们得有一台多核或者多处理器的计算机，而且多线程的程序写起来也有点小复杂。

但小明不傻啊，小明心想，mmp，又不是我一个人看的，为啥要我自己数，于是小明心生一计，回到班里，大家有福同享有难同当，老师现在让我数**萧炎**在书中一共出现了多少次，我自己数到明天也数不完，谁看的谁过来**大家一人数几页**，然后你们在下面数好了**汇总**一下交给我。

于是全班男生一人数了几十页，不到一个小时就数完了，小明成功渡过一劫。

这就是 Map - Reduce，我一个人算不过来了，我找十个人并行计算，最后把结果进行汇总，不用说也知道是什么思想了，数据结构中用的最多的**分而治之**。

当然，Map-Reduce肯定不止我们上面说的那么简单，具体实现细节还是略微有点繁琐的，详细的执行流程，原理到时候我们在Map-Reduce专题再细细分析。

## Yarn：

`Yarn`这个东西在`Hadoop2.x`时代才诞生，在遥远的`Hadoop1.x`时代，`Map-Reduce`不仅要负责**计算**，还要负责**资源调度**，简直是又当爹又当妈，一两天还好，时间长了`Map-Reduce`就受不了了，就向`Hadoop`总部提意见，总部肯定装作没听到啊，一个人干俩人的活儿不能再划算了。于是就不搭理`Map-Reduce`，后来有一天，`Map-Reduce`终于忍无可忍了，就甩袖子不干了，因为之前Map-Reduce又干计算又干资源调度，所以Map-Reduce甩袖子不干了，整个`Hadoop`计算和资源调度系统全都歇菜了。

耦合太严重，于是`Hadoop`觉得这不行，被Map-Reduce卡脖子可还得了？于是`Hadoop`又招了一个专门负责资源调度，就是`Yarn`，这样一来，Map-Reduce只负责计算，Yarn只负责资源调度，`Hadoop`内部瞬间和谐多了。再也没有出现过一人罢工，全员歇菜的问题了。

Yarn主要干四个事儿，分别是：

**ResourceManager（RM）：**

- 处理客户端请求。
- 监控`NodeManager`。
- 启动或监控`ApplicationMaster`。
- 资源的分配与调度。

**NodeManager（NM）：**

- 管理单个节点上的资源。
- 处理来自`ResourceManager`的命令
- 处理来自`ApplicationMaster`的命令

**ApplicationMaster（AM）：**

- 负责数据的切分。
- 为应用程序申请资源并分配给内部的任务。
- 任务的监控与容错。

**Container ：**

​    `Container`是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。

等。

## HDFS：

`HDFS `:` Hadoop`分布式文件系统（`Hadoop Distributed File System`),听名字就知道是`Hadoop`中负责文件存储部分的技术了。

`HDFS`相对于前面的`Map-Reduce`和`Yarn`就比较容易理解了，`HDFS`架构主要分为三个部分：

**NameNode（nn）**:

存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的`DataNode`等。

`NameNode`主要存储文件的元数据，比如我们去图书馆借书，`NameNode`存的就是这个图书馆所有书籍的目录，作者，文件属性，以及书的位置等信息。

**DataNode(dn)** ：

`DataNode(dn)`：在本地文件系统存储文件块数据，以及块数据的校验和。

还是上面那个图书馆的例子，如果`NameNode`主要存的是目录的话，那么`DataNode`就是存书的书架，也就是我们实际的数据实际是在`DataNode`上存放的。

**Secondary NameNode(2nn)：**

`Secondary NameNode(2nn)`：用来监控`HDFS`状态的辅助后台程序，每隔一段时间获取`HDFS`元数据的快照

看名字就知道了，和我们`Nginx`中讲的万一`Nginx`挂了是一个性质，你只有一个`NameNode`，万一不小心`NameNode`挂了，所有文件的元数据都没法儿访问，找不到文件的实际位置，那不就gg了吗，所以`Secondary NameNode(2nn)：`主要就起一个辅助备份的作用.

万一`NameNode`挂了，别怕，有`Secondary NameNode(2nn)`在，他那有备份，恢复都是小KS。



## 下面开始技术总结：

今天这篇文章，我们初略地讲了`Hadoop`的三个重要的组成部分，`Map-Ruduce` `Yarn` 和 `HDFS`文件系统，分别负责`Hadoop`的分布式计算，资源调度，分布式存储实现，每一个都不可或缺，正是这三项技术的在`Hadoop`内部的完美配合，造就了今天`Hadoop`在大数据领域的地位，看到这里，我想尽管我们可能还不知道Yarn内部是怎么协调资源的，MR是如何进行并行计算的，但是我相信，大家对于`Hadoop`一定有了一个初略的认识，下一篇文章，我们讲一步一步通过配置虚拟机，然后实现我们`Hadoop`的伪分布式环境的配置。

非常感谢能读到这里的朋友，你们的支持和关注是我坚持高质量分享下去的动力。

相关代码已经上传至本人github。一定要点个**star**啊啊啊啊啊啊啊

**万水千山总是情，给个star行不行**

[韩数的开发笔记](https://github.com/hanshuaikang/HanShu-Note)

欢迎点赞，关注我，**有你好果子吃**（滑稽）





